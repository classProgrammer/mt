
\section{Approach}
% was wird betrachted, was nicht        
% Domain wird betrachtet
% andere Sachen nicht
% gleiche test sätze und entitäten
% gleiche stories
The problem (sickness notification and vacation notification) needs to be evaluated to determine if the problem is suitable for chatbots.
Sickness notifications are a repetitive task, the task can be automated and requires simple Back-and-Forth communication hence the problem fits the description of \citet{buiildChatbotsPython}.
The same is true for holiday notifications since the idea of both remains the same.
The problem is suitable for chatbots since all three questions can be answered with yes.
The next step is to determined the converstaion type.
The two major chatbot conversation categories mentioned in Chapter \ref{chap:soa}: State-of-the-Art are goal-oriented 
and end-to-end conversations \cite{williams2017hybrid, bordes2016learning, rahman2017programming}.
A goal-oriented system helps a user to achieve a task \cite{rahman2017programming}.
In the case of a sicknes notification the system needs to aid and guide the user through the process to reduce the workload.
This description fits perfectly for goal oriented dialog.
The domain is clear and of limited size since the user can only ask about the sickness/vacation notification process and nothing else.
The bot also needs to retrieve specific data from the conversation to identify the person.
The retrieval process is a specific task with specific entities and fits a goal-oriented system.
In open-ended systems the conversation is not limited to a domain and the conversation can evolve in any direction.
This is definitely not the case for the sickness and holiday notifications because the problems are domain specific.
Therefore, goal-oriented technologies fit the the problem description.
End-to-end systems won't be considered in this thesis because their performance in goal-oriented settings is not good enough yet as 
\citet{bordes2016learning} mentioned.
The given problem of sickness notifications is a domain-specific/goal-oriented 
(\citet{deshpande2017survey, luis2015williams, braunEvaluatingNLU, williams2017hybrid}) 
task hence domain-specific frameworks are suitable.
% Framework selection
The framework selection for this thesis is based on chapter \ref{chap:soa} State-of-the-Art and Section \ref{sec:prereq} Prerequisites.
Section \ref{sec:prereq} describe the requirements of the company and chapter \ref{chap:soa} shows which technologies are 
used in papers, articles, and books.
To match the prerequisites at least one cloud (\citet{braunEvaluatingNLU, rahman2017programming}) and one local (\citet{braunEvaluatingNLU}) chatbot are needed and IBM Watson Assistant needs to be taken because an IBM technology is on the wish-list.
A common cloud technology is Dialogflow (\citet{braunEvaluatingNLU, dutta2017developing, singhbuilding, buiildChatbotsPython, rahman2017programming, ieee2018watson}) hence it is selected.
A common local standalone technology is Rasa (\citet{braunEvaluatingNLU, singhbuilding, rasabocklisch2017, buiildChatbotsPython, gregori2017evaluation}) and is the local tool of choice.
The chosen technologies are Dialogflow, IBM Watson (\citet{rahman2017programming, pharmacybot, ieee2018watson, gregori2017evaluation}), and Rasa to fulfill all requirements.
% prototyping
All three prototypes will be used to implement the same task.
An example convsersation of the sickness notification task is shown in Figure \ref{fig:sicknessflow}
They will be trained with the same data listed in the appendix 
in Table \ref{tab:sickness_utterances} and Table \ref{tab:vacation_utterances}.
They will have the same intents, entities, and utterances.
These steps are necessary to ensure a fair comparison.
The analysis of the sickness notification dialog is shown in Table \ref{tab:sick_data}.

\section{Training and Test Setup}
To test chatbot systems they need to be implemented.
A chatbot is based on natural langage processing and needs training data.


\section{Course of Action} % Ablauf
First of all, the problem needs to be analyzed and classified.
The problem can either be suitable or unsuitable for the use of chatbots.
It's suitable if the problem can be solved by simple back and forth communication,
is repretitive, and can be automated \citet{singhbuilding}.
Then the conversation needs to be analyzed.
In general, the conversation needs to be solvable through general conversation or 
task-oriented communication.
The conversation can be represented as flowchart like \citet{singhbuilding} did.
The required intents, entities, and actions need to be defined based on the conversation.
Training data needs to be created for the intents and entities where necessary.
The same trainig data is used for every technology to ensure a fair 
comparison of the results.
The prototypes are then developed based on the training data.
The resulting prototypes need to implement the same dialog structure.
It's either possible or impossible to implement the dialog structure with the 
chatbot technologies. 
If it's impossible to implement the dialog structure the technology 
won't be recommended.
Afterwards, the test data needs to be created for the comparison and evaluation of 
the chatbots.
The test data is the same for all bots.

\section{Comparison and Evaluation}
A main part of this thesis is the comparison and evaluation of the 
frameworks and the prototypes.
The frameworks and prototypes will be compared in the sickness/vacation domain.
% entity extraction
The two major tasks of chatbot systems are the entity extraction and the intent 
classification.
\citet{geyer2016named} compared frameworks based on their entity extraction
capabilities.
Based on the work of \citet{geyer2016named} the frameworks will be tested 
for their entity extraction capabilities.
This is measured by counting the true/false positives and true/false negatives.
These four values are used to calculate precision and recall which 
are used to calculate the f-score.
The f-score is the measurment criteria for the performance.
An f-score of 1.0 is the maximum which can be achieved.
The frameworks will be ranked based on their f-score.
The f-score will be calculate for each use-case relevant entity 
individually (date, date-span, person) and for all relevant entities
together.
This will show how good the individual entities of the frameworks are 
and how good the entity extraction works in general.
Rasa doesn't provide entities but the pipeline can be 
adjusted to include technologies which provide entities.
A popular technologies for date, time, and all sorts of 
numeric values is Duckling (Wit.ai).
Spacy is a technologie which provides the required person entity and 
it's available for Rasa.
The cloud frameworks all have built in system entities. 
% intent classification
The same process will be used for the intent classification task.
The intent classification provides a confidence score value.
The confidence score will be used to rank the intent classification 
capabilites in a second ranking.
The range is from zero to one where values close to zero are 
bad and values close to one are good.
The confidence score alone is not enough to do the second ranking 
since the technologies always pick the best fitting intent.
The best fitting intent doesn't have to be the correct/expected intent.
The technologie could say it's 60\% sure the intent none is correct 
and the expected sick intent only reaches 40\%.
In this case the none intent would be picked.
The confidence scores alone are biased since no matter 
which intent is recognized there will always be a value for 
each intent no matter the input.
The average confidence score will be calculated for the 
two use-cases individually and combined for both.
This is an indicator if a technology has problems with or excells
on a specific use-case.
The average confidence score should be as high as possible.
An average confidence below 50\% is low and indicates 
that the technology is not sure that the intent was 
classified correctly.
A low confidence score can be improved through more training data
in most cases. 
The intent classification capabilities need to be checked for the English and German 
language.
The potential users for further projects use German as input language.
The expectation is that there is small to no difference in the development process, 
that the same functionality is available for Germand and English,
that the performance is on an equal level, that the 
entity extraction works for both languages, and that 
the same predefined entities are available for both languages.

% implementation possible or not
\citet{singhbuilding} says the best evaluation criteria is if the 
task can be achieved.
This will be used as evaluation criteria and will be based on the 
design and prototype chapters.
The design chapter provides the blueprint which needs to be 
implemented with the different technologies.
The prototype section shows if the blueprint can be 
implemented successfully with a specific technology.
The technologies will be classified binary as true if it's possible and 
flase if it's impossible.
The expectation is that the implmentation is possible with 
all chatbot frameworks namely Dialogflow, Watson Assistant, and Rasa.
A successful implementation can't be expectd with LUIS.
LUIS is a NLU service and not a chatbot technology.
Hence, it doesn't offer a mechanism to handle dialogs which is 
necessary to implement a chatbot.
The Microsoft Bot Framework can be used to build chatbots 
and uses LUIS.
% price comparison
One of the main reasons why companies use or want to use chatbots is because they are cost efficient.
For this reason the prices of the chatbot frameworks need to be compared.
In general, cheap is treated better in this ranking than expensive.
This criteria does not make a statement about the quality of the framework.
For this reason the ranking should be reconsidered after the test when the 
quality ranking is available.
If a technolgy is good it's a candidate for the recommendation.
If a technology is bad the price doesn't matter because it will not be recommended.
Hence, a good and cheap technology is wanted. 
For the usage in a business application the prices of all version of the frameworks are relevant 
especially if an enterprise verison is offered.
The expectation is that the frameworks cost roughly the same and that 
the prices are easy to compare.
% portability
The ISO 25010\cite{iso25010} standard defines portability as an evaluation criterion for software systems.
Portability is a big issue with chatbot technologies.
One sub criteria for the evaluation is the number of providers where the chatbot 
can be deployed.
It's expected that the cloud technologies can run only in the cloud environment.
This criteria focues on Rasa to see where and how it can be deployed.
Another aspect fo portability is the number of devices a developer can work with 
% no of devices
with a focus on the hardware and software which needs to be present to run the 
framework.
The expectation is that a cloud chatbot can be developed from everywhere 
as long as a web-browser and an internet connection are available.
It's expected that Rasa is at a disadvantage in this category.
% migration
The migration from one technology to another is an aspect of portability.
It's expected that all technolgies safe the data differently and that it's not 
easy to migrate between them.


% Domain
% Knowledge Base bilden
% Intents
% entities
% utterances
% test set bilden
% TP
% TN
% FP
% FN
% Stories bauen
% Stories umsetzen
% testen
% deployen für gleiche Bedingungen
% testen und vergleichen