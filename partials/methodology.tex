\section{Approach} % what's included, what's excluded and why
% problem analysis
The first step in the design process of a chatbot is the problem analysis.
As mentioned in \citet{folstad2017chatbots}, the design focus of chatbots lies in the conversation.
For this reason, a basic conversation has been created and analyzed 
to extract the required intents and entities.
The example conversation of Figure \ref{fig:sicknessflow} has been 
analyzed in Table \ref{tab:conversation_data} and was used to create the dialog 
flow-chart shown in Figure \ref{fig:conversationflow}. 
The flow-chart has been used as the blueprint for the chatbot prototypes.
All prototypes had to implement the same dialog structure to make 
a fair comparison possible.
% suitable problem
The extracted information was used to determine if the given problems are 
solvable through the use of a chatbot.
The three criteria \citet{singhbuilding} mentioned have been satisfied by 
the problem description.
The sickness notification has been classified as repetitive since the main 
process is about data collection for both problems.
The chatbot needs to identify the type of the users message which can either be 
sickness notification or vacation request.
Then the data needs to be extracted by the chatbot.
For a sickness notification, the name of the person is a required input and 
the return date is an optional parameter.
For the vacation request, the name of a person and a date-span are required. 
The process can be automated since the interaction can be done between 
the chatbot and the user without further interaction of a third party.
The two use-cases are also solvable via simple back and forth communication 
because the chatbot just needs to classify a sentence and 
extract data. 
% key functionality of chatbots
As mentioned in Chapter \ref{chap:basics} Basics the classification of sentences and extraction 
of data are the two key features chatbots offer.
The final dialog flow for the use-cases of Figure \ref{fig:conversationflow}
confirmed that both of the use-cases are solvable via simple back and forth 
communication.
% chatbot category
There are three major chatbot categories and the sickness notification and 
vacation request problem have been classification as task-oriented and are 
tied to a domain.
Task-oriented approaches have been described and used in 
\citet{deshpande2017survey, luis2015williams, braunEvaluatingNLU, williams2017hybrid}.
The chatbot has to be able to answer questions in the domain of sickness notifications 
and vacation requests.
It's not required to answer any questions that are unrelated to the given domain.
The chatbot needs to extract specific data from the sentences which is the second 
indicator that the problem is task-oriented.
The third indicator for a task-oriented problem is that the chatbot has to collect 
information from the 
conversation to achieve a specific task.
In the case of this thesis, the tasks are the submission of a sickness notification
and vacation request to an endpoint. 
Hence, the task-oriented chatbot approach has been chosen for this thesis.
The menu-driven approach has not been chosen because the given problems require a mechanism 
to input dates and person names in full and partial sentences.
This description doesn't fit the menu-driven approach since it uses numbers as input.
The third major chatbot type found in literature is the open-ended approach found in 
\citet{williams2017hybrid, bordes2016learning, rahman2017programming}.
The open-ended approach has no specific goal and is not limited to a domain.
As mentioned before the problem is based on achieving two tasks.
This disqualifies the open-ended approach since it's not meant to
collect data to achieve a task.
Furthermore, as \citet{bordes2016learning} mentioned, the open-ended approach is not 
yet able to perform well enough in task-oriented settings to be considered for this 
thesis.
As \citet{williams2017hybrid} showed, it's possible to combine the open-ended and 
task-oriented approaches by adding state-related information.
The hybrid approach works better than the classic open-ended approach but 
is not compared with task-oriented technologies.
Since no comparison between the hybrid and task-oriented approach has been available 
solely task-oriented technologies have been considered for this thesis.
% domain
For this thesis, the domain has been defined as sickness notifications and vacation requests.
The chatbot prototypes function only inside of the given domain since further 
functionality hasn't been defined in the requirements section.
The functionality only covers the two request types of sickness and vacation and basic 
structures like hello, bye, thank you, yes and no to build the conversations.
No meaningful response can be expected if something else is used as input.
% framework selection
There are a lot of chatbot frameworks available.
As mentioned by \citet{kane2016role}, the two major categories for chatbot frameworks 
are cloud-based solutions that are developed via a website and local standalone applications.
The framework selection for this thesis was based on chapter \ref{chap:soa} State-of-the-Art 
and Section \ref{sec:prereq} Prerequisites.
Section \ref{sec:prereq} describe the requirements of the company and Chapter \ref{chap:soa} 
shows which technologies are 
used in papers, articles, and books.
To match the prerequisites at least one cloud (\citet{braunEvaluatingNLU, rahman2017programming}) 
and one local (\citet{braunEvaluatingNLU}) chatbot are needed and IBM Watson Assistant (\citet{rahman2017programming, pharmacybot, ieee2018watson, gregori2017evaluation}) needs to be taken because an IBM technology is on the wish-list.
A common cloud technology is Dialogflow (\citet{braunEvaluatingNLU, dutta2017developing, singhbuilding, buiildChatbotsPython, rahman2017programming, ieee2018watson}) hence it is selected.
A common local standalone technology is Rasa (\citet{braunEvaluatingNLU, singhbuilding, rasabocklisch2017, buiildChatbotsPython, gregori2017evaluation}) and is the local tool of choice.
The chosen chatbot technologies were Dialogflow, IBM Watson, and Rasa.
The selection fulfilled all requirements by the company.
Additionally, LUIS\cite{luis2015williams} was chosen for the NLU comparison since it 
has been evaluated as the NLU technology with the best performance by \citet{braunEvaluatingNLU}.
LUIS has been mentioned or was used by \citet{singhbuilding, buiildChatbotsPython, rahman2017programming, dutta2017developing}, 
and \citet{gregori2017evaluation}.
% training data
To ensure a fair comparison the chatbot prototypes were implemented using the same 
dialog structure of Figure \ref{fig:conversationflow}.
An example conversation of the sickness notification task is shown in Figure \ref{fig:sicknessflow}
The NLU part of all four technologies has been trained with the same training data to 
ensure a fair comparison with the same initial state.
The data used for training has been listed in
Table \ref{tab:sickness_utterances}, \ref{tab:vacation_utterances}, \ref{tab:sickness_utterances_de}, 
and \ref{tab:vacation_utterances_de}.
The prototypes have been implemented with the same intents and utterances.
The training data for the prototypes has been defined by the author.
\begin{table}[h]
    \centering
    \begin{tabular}{ c | l | c | c   }
        \multirow{2}{*}{No} & \multirow{2}{*}{Utterance} & Person & Date \\ 
                 &&         Entity & Entity                 \\ \hline \hline
        1 & I am sick & \xmark & \xmark\\ \hline 
        2 & sickness notification & \xmark & \xmark\\ \hline 
        3 & I am ill & \xmark & \xmark\\ \hline 
        4 & [Alfred Mayer] is sick & \cmark & \xmark\\ \hline 
        5 & my colleague [Maria M\"uller] is sick until [wednesday] & \cmark & \cmark\\ \hline 
        6 & colleague [Simone Bauer] is ill & \cmark & \xmark\\ \hline 
        7 & report [Franz Dorfer] sick & \cmark & \xmark\\ \hline 
        8 & [Stefan Weber] is ill till [Friday] & \cmark & \cmark\\ \hline 
        9 & sick [Emma Wagner] [6th of June] & \cmark & \cmark\\ \hline 
        10 & [Sophia Richter] feels sick today & \cmark & \xmark\\ \hline 
    \end{tabular}
    \caption{Sickness Training Utterances English} \label{tab:sickness_utterances}
\end{table} \noindent
% entities
It wasn't possible to use the same entities since they were provided by different 
technologies or not at all. 
Dialogflow and LUIS provided all required entities by default, Rasa needed external 
tools to provide the entities, and for Watson Assistant a person entity had to be 
created from scratch.
For the German language, LUIS provided no person entity and it had to be created from 
scratch. 
This has been done to make the performance comparison as fair as possible regarding the NLU section.
The same training data for all technologies approach has been used 
by \citet{braunEvaluatingNLU, dutta2017developing} 
and \citet{gregori2017evaluation} and was adopted for this thesis to enable a fair comparison.
% tests
The two key functionalities of chatbots have been tested inside of the given domain to answer 
which chatbot technology is the best to solve the given problem.
The key functions of chatbots are the intent classification and entity extraction.
The entity extraction capabilities have been tested by \citet{geyer2016named}.
The intent classification and entity extraction has been tested by \citet{braunEvaluatingNLU} 
using precision, recall, and f-score values.
The approach with precision, recall, and f-score has been adopted for this thesis 
since it defines an objective numeric value for the performance of a chatbot system 
and prevents subjective bypass for tests.
The intent classification data used for all technologies has been listed in 
Table \ref{tab:sickness_intent_classification},
\ref{tab:vacation_intent_classification}, \ref{tab:sickness_intent_classification_de} and \ref{tab:vacation_intent_classification_de}.
The entity extraction test data has been listed in Table \ref{tab:person_entity_extraction_recognition}, 
\ref{tab:date_entity_extraction_recognition}, \ref{tab:date_entity_extraction_recognition2}, 
\ref{tab:date_span_entity_extraction_recognition}, and Table \ref{tab:date_span_entity_extraction_recognition2}.
The test evaluation focuses solely on domain-specific information since the main purpose 
of this thesis is a proof of concept through prototyping.
% domain test influence
The result of \citet{braunEvaluatingNLU} showed that the domain had small to no influence on the 
performance of the tested technologies.
Hence, a good technology is expected to perform well in any domain and a bad technology is expected
to perform measurably worse than a good technology in any setting.
In \citet{braunEvaluatingNLU} it was stated explicitly that different technologies should be tested 
with domain-specific data before one is selected for the actual product.
The actual interesting performance of a chatbot is the domain-specific performance.
If a chatbot technology shows great performance in general but performs badly in the 
given domain, it shouldn't be used for the domain.
Hence, the general performance is not interesting for the development of a 
domain-specific bot.
For this reason, only domain-specific training and test data were used.
% user study
Another common testing approach for chatbots are user studies as mentioned 
in \citet{evaluateChatbotsShawar2007}.
User studies are recommended for customer-facing chatbot to increase the quality of the 
product and gather communication information between the chatbot and the users.
User-studies are not part of this thesis since they are not required for a proof of concept 
through prototyping.
A user study also doesn't provide any information about the development perspective which is 
a key part of the thesis.
% psychological aspects
The psychological aspects mentioned by \citet{folstad2017chatbots, brandtzaeg2018chatbots}
and \citet{GO2019304} have been partially applied.
The general rule that a chatbot should tell the user that he's talking to a bot 
was applied.
The advanced rules for humanness are interesting for user studies and should be considered 
for future projects.
They are not relevant for the proof of concept because there are no user studies in this thesis.


\section{Comparison and Evaluation}\label{sec:comparison_and_eval}
% test setup: data 
A major part of this thesis has focused on the evaluation and comparison of the 
developed prototypes.
The training and test data used for the comparison is domain-specific and no other 
data has been used.
The training and test data sets were used for the evaluation of the entity extraction and 
intent classification capabilities of the framework.
% entity extraction
It was impossible to test the entity extraction capabilities of the frameworks unbiassed since 
the person entity was not predefined for Watson Assistant and had to be created from scratch.
An entity created by the developer might overfit or suffer from a small amount of training data.
This is a bias in the test setting since the performance is dependent on the developer and not 
on the technology alone.
With Watson Assistant it wasn't possible to mark entities in the training sentences when 
German is selected as the language.
This rendered Watson Assistant useless for the German input language.  
The Rasa framework doesn't offer any predefined entities itself and relies on other 
optional technologies like Spacy and Duckling.
The use of Spacy for date and date-spans was possible but the result date wasn't in standardized 
format.
This lead to the use of Duckling since it provided the necessary standardization for date and 
date-span entities.
Furthermore, Dialogflow offered two entities that can handle date-spans while 
Watson Assistant offers none.
For Watson Assistant two separate dates were used instead.
Both date-span entities of Dialogflow were tested to ensure the best possible 
result regarding the tests.
The entities which were defined by the problem analysis of the user-cases are 
the person, date, and date-span entity.
Only those three entities have been included in the entity extraction tests.
For the evaluation of the results the recall, precision, and f-score values were used 
as \citet{braunEvaluatingNLU} did.
To calculate the values the TP, FP, and FN values are counted for each individual test case.
The comparison of the frameworks has been difficult since some entities are not available 
using certain technologies.
Watson Assistant and Duckling had no person entity and LUIS had no person entity for the 
German language.
In the case of Dialogflow two entities were available that could be used for the date-span 
extraction.
The available enities were listed in Table \ref{tab:entity_extraction_recognition}.
To make the values comparable the result was calculated for each individual entity, 
the combination of date and date-span, 
and the combined score over across all entities.
% intent classification
The second major function of chatbots is the intent classification.
The intents were trained with the same utterances for all four technologies 
to create a fair test setup.
To measure the performance the precision, recall, and f-score values were used to 
provide an objective value.
As mentioned in Chapter \ref{chap:basics} Basics, the NLU services of all four 
frameworks provide a confidence value.
The confidence value is a response that represents how well the input fits an intent.
The result evaluation of this thesis has been extended with the confidence score since 
it is an indicator of how good the training worked for the frameworks and if 
additional training data would have been necessary.
The additional value standard deviation has been added to compare how consistent the 
confidence scores of the chatbots were. 
The confidence scores were shown for the correct intent no matter if the intent 
was identified correctly or not to calculate and average confidence 
score across all tests.
The average confidence score provides another quality metric.
A high average confidence score combined with a high f-score indicates that the 
chatbot classifies intents reliably and vice versa.
A small standard deviation in combination with high average confidence indicates
that the chatbot classifies intents reliably with a high confidence score. 
The intent classification was tested for English and German.
This was necessary since the 3 Banken IT has it's locations in Austria
which makes German the language of choice for potential users.
The expectation for the German tests was that there is no difference to the 
English tests which was not met since e.g. LUIS had no person entity for 
the German language.
The performance expectation was that the German bot is on the same level 
as the English bot regarding entity extraction and intent calssification.
% implementation possible?
As \citet{singhbuilding} mentioned, the best evaluation criterion is if the 
underlying task can be achieved or not.
This evaluation criterion has been adopted for this thesis since it's the 
most relevant for a recommendation of a technology.
As a result value for this evaluation, a binary boolean criterion was chosen.
Either it was possible to build a prototype that implemented the design or it was impossible.
The evaluation didn't include an opinion or how hard the implementation was with a design.
Since LUIS is an NLU technology and not a chatbot technology it was excluded from this test
because it offers no dialog handling mechanism.
It would have been unfair to include an NLU technology since it's not meant to handle 
dialogs.
The Microsoft Bot Framework uses LUIS and offers dialog handling but wasn't used in 
this thesis and is therefore not part of this test.
% speech recognition
For future project speech recognition capabilities are on the wishlist of the 
3 Banken IT.
For this reason the speech-to-text and text-to-speech services offered for the 
chatbot technologies were compared based on their price.
Chatbots which offer speech functionality can be used through 
voice interfaces in the future.
The second evaluation criterion in the speech recognition category was
if speech services are offered by the provider. 
It was expected in general that each framework offers speech services for their 
chatbot technology since these are two closely tied topics.
% price comparison
A key factor for the use of chatbots is the price.
That the price plays an important role was mentioned in \citet{buiildChatbotsPython} 
for instance.
None of the articles used for this thesis compared the prices of the 
available technologies.
The goal of the price comparison was to find out which technologies are cheap and which are 
expensive.
In combination with the other evaluations, the expectation was to find a cheap technology 
which performs well.
The price of a chatbot has been calculated for different categories since the 
prices were intransparent and hard to compare.
The first category was the price for the chatbot technologies, the second 
one eas the price for hosting, and the third category was the price 
for speech-to-text and text-to-speech services.
The prices for the chatbot technology for the enterprise edition of Rasa 
and Watson Assistant is not listed on the website since it's calculated 
individually.
The prices for the Microsoft Bot Framework were calculated by adding the price
for the Microsoft Bot Framework and LUIS.
The prices for Watson Assistant are calculated per user per month while the price for
Dialogflow, LUIS, and the Microsoft Bot Framework was based on the number of requests.
Rasa is free by default and was excluded from the price calculation since 
no prices were listed on the website.
The prices for the text-to-speech and speech-to-text services were comparable for
Watson Assistant, Microsoft Speech Services, and Dialogflow.
Rasa didn't offer text-to-speech and speech-to-text services at all.
The general expectation was that the frameworks cost roughly the same but 
the prices were hard to compare or not comparable at all.
% portability 
Another evaluation criterion used for this thesis is the portability of 
software systems as defined in the ISO 25010\cite{iso25010} standard.
The portability was chosen since the comparison of the cloud 
technologies with a local technology was interesting from a 
development point of view.
The first factor discussed in this thesis were the necessary tools 
since they determine how portable the development environment of the 
chatbots are.
%% local vs cloud
The portability of the development environment of the local technology 
Rasa in contrast to the cloud chatbot technologies was the 
main focus of this evaluation.
The second factor chosen was the number of providers where the 
chatbot can be deployed.
The main focus lay on cloud technologies since the expectation was
that they can only run in the environment of the provider and are 
not portable at all.
The third portability category chosen was how flexible the development
of chatbots is regarding the devices.
The expectation was that cloud technologies are developed in a 
web browser and can be developed from almost anywhere while 
the local technology requires a development environment and is 
comparably unflexible.
%% migration
Another aspect of portability is the migration from one technology to another.
It was expected that all technologies safe the data differently and that it's not 
easy to migrate between them.
% project setup
For the development of a chatbot, the project setup complexity plays an important 
role and was evaluated in this thesis.
The main focus of this test was Rasa since the setup complexity was interesting 
for the local technology.
The setup of the cloud technologies was expected to be easy since the providers 
take care of the setup for the customers.
% deployment complexity
The deployment of chatbot systems is an important aspect when local and cloud 
technologies are compared.
While it was expected that a cloud technology produces no deployment overhead 
the opposite is expected for a local technology since the deployment needs to 
be done by the developer.
For the local technology, the Docker deployment and setup of a local Python environment were 
included in the evaluation.
Especially the deployment using Docker has proven as interesting for 
future projects because of the flexibility and simplicity. 
% learnability
The ISO 25010\cite{iso25010} defines learnability as sub-criterion of usability as measurement
metric for software systems.
The learnability is important from a development perspective since an easy to learn and 
use technology is the optimal case when the performance is good.
The evaluation of the project setup and deployment complexity was included in 
the learnability since they are part of the development of a system.
%% predefined entities
As mentioned before, the chatbot technologies use entity extraction to extract data from text.
The entity extraction is a part of the development process of a chatbot
and it takes time to define good entities.
All of the chatbot technologies offer predefined entities that are ready to use.
As a criterion, the number of predefined entities was defined as a measure since 
lots of predefined entities can save lots of development time for future projects.
If a required entity is available for a given problem the developer doesn't need 
to create one.
The second measurement criterion it the entity category is if all required 
entities for the use-cases of this thesis were predefined by the chatbot technology.
The technologies where all required entities were predefined are better suitable 
to solve the given problem.
It was also evaluated how hard it is to create new intents, entities, training phrases,
and dialogs.
The expectation was that it is equally complicated for each technology.
%% design of conversations, nodes, and stories
As mentioned by \citet{folstad2017chatbots} the design of chatbots is all about the
conversation.
Hence, the most important aspect was the creation of dialogs.
The frameworks Dialogflow and Watson Assistant offered dialog nodes 
to create and structure conversations.
A dialog node is one step of the conversation and can be followed by another 
dialog node.
A dialog node was e.g. the classification of the sickness notification intent
followed by the collection of the name and return date to the response of the system.
Rasa offered stories to represent a dialog.
A story represents a whole conversation path from start to finish.
The start was a greeting line and the end the goodbye response for instance.
%% form data
An important part of the conversations required for this thesis was the 
extraction of form data and has been evaluated regarding the 
complexity.
Rasa was the only technology tested where programming skills were necessary to
extract form data from the conversation. 
% customization possibilities
%% pipeline: custom components
For developers, an important factor are the customization possibilities.
It's an advantage for when the pipeline can be fine-tuned to increase the 
performance or add special custom components.
The only tested framework which offered pipeline customization was Rasa.
A developer can even create new custom components and include them in the 
pipeline. 
This is interesting for very specific company requirements, research, and fine 
tuning to increase performance.
The other tested technologies didn't even display the configuration of the pipeline.
When Rasa is used for development the pipeline is adjustable to the 
developers needs.
For the development of the prototype with Rasa the technologies Spacy and 
Duckling were added to the pipeline for entity extraction.
This was not possible with the other frameworks since the pipeline can't 
be adjusted at all.
%% story vs dialog node
The stories used by Rasa were adjustable fine granular compared to the dialog
node approach of Dialogflow and Watson Assistant.
A story could be used to execute multiple actions and display multiple responses in a
row.
Watson Assistant can't execute multiple actions but can call the webhook where 
the request can be processed.
Dialogflow can't execute multiple actions or display multiple responses. 
%% action server VS regular form data
With Rasa, the default form action was implemented using Python while no 
programming skills were required for form actions using Watson Assistant
and Dialogflow.
The advantage of a programming language for form actions is that the concepts of a programming 
language are available for e.g. the validation of entries and calling external services.
Hence, a comparison of the programming based approach with the cloud approach was 
included in this thesis.
% framework concepts
%% intents, entities, utterances
As discussed in Chapter \ref{chap:basics} Basics, the concepts used by the 
frameworks are interesting.
The base concepts intent, entity, and utterance are present in literature and 
it was expected that these concepts are also present in the frameworks.
% communication
Another important aspect is the communication with the chatbot services.
%% JSON format
In general, JSON is the request and response format for all tested technologies.
All the technologies offered a REST interface for communication.
%% meta info
The messages differed when the content was compared since 
LUIS and Dialogflow sent metadata while Watson Assistant and Rasa didn't.
These are two very different approaches which were evaluated for 
positive and negative aspects.
The meta-information can be used in the backend for future projects to 
create e.g. statistics.
% process external information
The communication can also be seen from the other side when a service sends 
additional information to the chatbot.
It was evaluated how easy it was to process additional information
in a chatbot.
The expected result was that Rasa is the easiest technology for processing 
information since it's the only technology which uses a programming 
language for data processing.
% training capabilities
Another big difference between Rasa and the other technologies were the 
training capabilities.
%% live training
Live training is offered by Rasa while all the other technologies 
were solely trained with the training data defined by the developer.
When live training is used the created stories are expected to be closer 
to a real-life scenario because the developer has to go through the conversation 
step by step.
This can prevent unnatural conversations since the developer creates the conversation 
step by step.
% user interface design
In the ISO 25012\cite{iso25010} defines the user interface aesthetics under the section 
usability. 
Hence the user interfaces of the frameworks were also compared regarding simplicity.
%% how simple, how easy to orient
This was evaluated from a subjective point of view.
The interface of a framework was evaluated as easy to use when the overall structuring 
was easy to understand and the prototype was easy to implement.


\section{Course of Action} % Ablauf
After the problem had been analyzed the dialog flow-chart was 
created.
Based on the flow-chart the required intents and entities were defined.
The required intents were sickness notification and vacation request.
For each use-case one intent was necessary.
The conversation built in the flow-chart made the required entities visible.
For the sickness notification the name of a person and an optional 
return date were required.
The vacation request needed the name of the person and a date-span.
The resulting entities were person, date, and date-span.
For each intent, 10 training sentences were created in English and 
10 were created in German.
The test sentences were used to develop a German and English prototype 
with each technology.
For the entities and intents, test sentences were defined.
The entity test sentences were evaluated as TP, FP, TN, and FN.
Based on these values the precision, recall, and f-score was calculated 
to provide an objective evaluation.
The same approach was used for the evaluation of the intent classification
plus the additional properties for the confidence and standard deviation.
For each test category as summary was created to compare the 
performance of the technology for each category.
The frameworks were evaluated based on the criteria listed in 
Section \ref{sec:comparison_and_eval}.
The results were used to rank the frameworks in different categories 
which show the strengths and weaknesses to make a final recommendation for 
further projects.
Furthermore, the entity extraction and intent classification results in 
English and German show which technology performed best in the 
given domain.