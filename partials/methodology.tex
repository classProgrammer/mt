\section{Approach} % what's included/excluded and why
% problem analysis
The first step in the design process of a chatbot is the problem analysis.
As mentioned in \citet{folstad2017chatbots}, the design focus of chatbots lies in the conversation.
The analysis of the example conversation led to the identification of the intents and entities required for the use-cases.
Figure \ref{fig:sicknessflow} shows the example conversation and Table \ref{tab:conversation_data} the analysis.
Figure \ref{fig:conversationflow} shows the resulting flow-chart for the use-cases.
The flow-chart is the blueprint for the chatbot prototype development.
This ensured that the dialog structure is the same for all bots making a fair comparison possible.

% suitable problem
The problem proofed to be solvable with chatbots based on the problem analysis.
As mentioned before, three criteria decide if the problem is suitable or not.
The flow-chart clearly shows that both use-cases are solvable through back and forth communication, making the first statement valid.
The flow-chart also shows that both use-cases are repetitive data collection tasks.
The chatbot needs to identify the type of user message that can either be a sickness notification or vacation request.
Then the required data is extracted from the message.
For the sickness notification, the required data is a name, and the optional parameter is the return date.
The required parameters for the vacation request are the name of the person and a date-span or a start and end date.
Hence, the second statement of \citet{singhbuilding} is also valid since the problem is repetitive.
The communication is solely between the user and the bot without the interaction of a third party.
This means that the problem is automatable since no interaction with a third party is necessary.
To summarize, all three statements are valid for the given problem, and the use-cases are suitable for chatbots.

% key functionality of chatbots
As mentioned in Chapter \ref{chap:basics} Basics, the classification of sentences and extraction of data are the two key features chatbots have to offer.

% task-oriented chatbots
The given problem is task-oriented and tied to a domain.
The three major chatbot approaches are task-oriented, menu-driven, and open-ended. 
\citet{deshpande2017survey, luis2015williams, braunEvaluatingNLU, williams2017hybrid} use and describe task-oriented approaches.
Task-oriented chatbots offer limited, domain-specific functionality. 
Questions outside of the domain are out of scope and not relevant.
The chatbot needs to extract specific data from the sentences, which is an indicator that the problem is task-oriented.
The second indicator that the problem is task-oriented is that the chatbot has to collect information from the conversation to achieve a specific task.
The chatbot has to be able to answer questions in the domain, which consists of sickness notifications and vacation requests.
It is not required to answer any questions that are unrelated to the given domain.
A limited set of operations also fits the requirements.
To conclude, the task-oriented approach is a perfect match since the description meets all requirements.

% menu-driven chatbots
The given problem can be solved theoretically by the menu-driven approach, which is not as suitable as the task-oriented approach in general.
The given problem requires a mechanism to input dates and person names in full and partial sentences to provide a natural user experience.
The menu-driven approach uses numbers to navigate a user through a menu.
The number one cloud be used for sickness notifications and two for vacation requests. 
Then the user inputs the name and dates and confirms the information.
To summarize, it is possible to use the menu-driven approach, but it would neither be ideal nor pleasant.

% open-ended chatbots
The third major chatbot type found in literature is the open-ended approach used in \citet{williams2017hybrid, bordes2016learning}, and \citet{rahman2017programming}.
The open-ended approach has no specific goal, is not limited to a domain, and has problems with collecting specific data.
The collection of data to achieve a task is crucial to implement the use cases, which is an indicator that this approach is unsuitable.
Furthermore, as \citet{bordes2016learning} mentioned, the open-ended approach is not yet able to perform well enough in task-oriented settings to be considered for this thesis.
The analysis showed that both use-cases are task-oriented.
This is the second indication that this approach is not the right one.

% hybrid
\citet{williams2017hybrid} combined the open-ended and task-oriented approaches by adding state-related information to and open-ended system.
The results showed that the hybrid approach works better than the classic open-ended approach, but the comparison with task-oriented technologies is missing.
Hence, it is impossible to tell if a hybrid approach makes sense for a task-oriented problem or not.
Open-ended approaches usually perform terribly in task-oriented settings, which makes the statement of \citet{williams2017hybrid} irrelevant since better than terrible is not precise.
To summarize, the task-oriented approach is a perfect fit for the requirements, while the open-ended approach proved unsuitably.
The hybrid approach is not used since the comparison with a task-oriented approach was not provided.
The menu-driven approach could be used but is not as pleasing as the task-oriented one.

% domain
The domain for this thesis is sickness notifications and vacation requests.
The prototypes only provide domain-relevant functionality since further functionality is not required.
The functionality only covers the two request types sickness and vacation and basic structures like hello, bye, thank you, yes, and no to build the conversations.

% framework selection
Dialogflow, LUIS, Rasa, and Watson Assistant were selected for prototyping.
In general, lots of chatbot frameworks are available.
As mentioned by \citet{kane2016role}, the two major categories for chatbot frameworks are cloud-based solutions developed via a website and local standalone applications.
The framework selection for this thesis was based on chapter \ref{chap:soa} State-of-the-Art and Section \ref{sec:prereq} Prerequisites.
Section \ref{sec:prereq} describes the requirements of the company, and Chapter \ref{chap:soa} shows the technologies present in papers, articles, and books.
To match the prerequisites at least one cloud (\citet{braunEvaluatingNLU, rahman2017programming}) and one local (\citet{braunEvaluatingNLU}) chatbot are needed.
IBMs Watson Assistant (\citet{rahman2017programming, pharmacybot, ieee2018watson, gregori2017evaluation}) is inevitable because it is on the wish-list of the company.
A common cloud technology is Dialogflow (\citet{braunEvaluatingNLU, dutta2017developing, singhbuilding, buiildChatbotsPython, rahman2017programming, ieee2018watson}) hence it is selected.
A common local standalone technology is Rasa (\citet{braunEvaluatingNLU, singhbuilding, rasabocklisch2017, buiildChatbotsPython, gregori2017evaluation}) and is the local tool of choice.
The chosen chatbot technologies were Dialogflow, IBM Watson, and Rasa.
Additionally, LUIS\cite{luis2015williams} was added for the NLU comparison.
It was the chatbot technology with the best NLU performance in \citet{braunEvaluatingNLU}.
LUIS has been mentioned or was used by \citet{singhbuilding, buiildChatbotsPython, rahman2017programming, dutta2017developing}, 
and \citet{gregori2017evaluation}.

% training data
All prototypes use the same training data.
Figure \ref{fig:conversationflow} shows the dialog structure, which was implemented with all technologies to ensure a fair comparison.
Figure \ref{fig:sicknessflow} shows an example of a conversation of the sickness notification task. 
The NLU part of all four technologies has also been trained with the same training data to ensure a fair comparison with the same initial state.
The data used for training has been listed in
Table \ref{tab:sickness_utterances}, \ref{tab:vacation_utterances}, \ref{tab:sickness_utterances_de}, 
and \ref{tab:vacation_utterances_de}.
The same training data also means that all technologies have the same intents, entities, and utterances.
The training data for the prototypes has been defined by the author which is a valid approach for prototyping.
\begin{table}[h]
    \centering
    \begin{tabular}{ c | l | c | c   }
        \multirow{2}{*}{No} & \multirow{2}{*}{Utterance} & Person & Date \\ 
                 &&         Entity & Entity                 \\ \hline \hline
        1 & I am sick & \xmark & \xmark\\ \hline 
        2 & sickness notification & \xmark & \xmark\\ \hline 
        3 & I am ill & \xmark & \xmark\\ \hline 
        4 & [Alfred Mayer] is sick & \cmark & \xmark\\ \hline 
        5 & my colleague [Maria M\"uller] is sick until [wednesday] & \cmark & \cmark\\ \hline 
        6 & colleague [Simone Bauer] is ill & \cmark & \xmark\\ \hline 
        7 & report [Franz Dorfer] sick & \cmark & \xmark\\ \hline 
        8 & [Stefan Weber] is ill till [Friday] & \cmark & \cmark\\ \hline 
        9 & sick [Emma Wagner] [6th of June] & \cmark & \cmark\\ \hline 
        10 & [Sophia Richter] feels sick today & \cmark & \xmark\\ \hline 
    \end{tabular}
    \caption{Sickness Training Utterances English} \label{tab:sickness_utterances}
\end{table} \noindent

% entities
It was impossible to use the same entities since they are different for each technology.
It was necessary to create an entity from scratch for Watson Assistant and LUIS (in German) since no predefined person entity was available.
In Engish, Dialogflow and LUIS provided all required entities by default. 
Rasa needed external tools to provide the entities.
The missing entities were added to the frameworks to make the NLU performance comparison as fair as possible.
The same training data for all technologies approach has been used 
by \citet{braunEvaluatingNLU, dutta2017developing} and \citet{gregori2017evaluation} and was adopted for this thesis to enable a fair comparison.

% tests
The two key functionalities of chatbots have been tested inside the given domain to answer which chatbot technology is the best to solve the given problem.
The key functions of chatbots are the intent classification and entity extraction.
The entity extraction capabilities were tested by \citet{geyer2016named}.
The intent classification and entity extraction was evaluated in \citet{braunEvaluatingNLU} using precision, recall, and f-score values.
The precision, recall, and f-score values are the base values for the evaluation of the entity extraction and intent classification capabilities.
This approach provides an objective numeric value for a chatbot system's performance and prevents subjective bypass for tests.
The intent classification data used for all technologies has been listed in 
Table \ref{tab:sickness_intent_classification},
\ref{tab:vacation_intent_classification}, \ref{tab:sickness_intent_classification_de} and \ref{tab:vacation_intent_classification_de}.
The entity extraction test data has been listed in Table \ref{tab:person_entity_extraction_recognition}, 
\ref{tab:date_entity_extraction_recognition}, \ref{tab:date_entity_extraction_recognition2}, 
\ref{tab:date_span_entity_extraction_recognition}, and Table \ref{tab:date_span_entity_extraction_recognition2}.
The test evaluation focuses solely on domain-specific information since the main purpose of this thesis is a proof of concept through prototyping.

% domain test influence
The result of \citet{braunEvaluatingNLU} showed that the domain had small to no influence on the performance of the tested technologies.
If the results can be trusted, good technologies will perform excellently no matter if the environment is domain-specific or not.
A lousy technology will perform poorly in any setting.
As \citet{braunEvaluatingNLU} said, different technologies should be tested with domain-specific data to determine which is the best fit for the given problem.
The domain-specific performance is the relevant performance since it has a big influence on the product.
A chatbot technology that performs great in general but poorly in the given domain is of no value.
All in all, The best technology is used to implement the actual product and not the technology that performs best in general domain-independent cases.
The prototypes of this thesis were implemented and tested solely with domain-specific training and test data.

% user study
As mentioned by \citet{evaluateChatbotsShawar2007}, user studies are another common approach to test chatbot systems.
They are recommended for customer-facing bots to increase the quality of the product and gather data about the human bot interaction.
User-studies are not part of this thesis.
A proof of concept through prototyping user studies are not required.
Furthermore, a user study does not provide any information about the development perspective, which is a key part of the thesis.

% psychological aspects
The psychological aspects mentioned by \citet{folstad2017chatbots, brandtzaeg2018chatbots} and \citet{GO2019304} have been partially applied.
The general rule that a chatbot should tell the user that he is talking to a bot was applied.
For further projects, the humanness of bots is an important factor and should be evaluated and implemented.
The humanness is an exciting topic for user-studies and can significantly increase user experience and acceptance.
Standard approaches are giving the bot a human name, gender, and face.
Amazons Alexa is one example of a bot with a human name, gender, and a voice.
However, it is not relevant for the proof of concept because there are no user studies in this thesis.


\section{Comparison and Evaluation}\label{sec:comparison_and_eval}
% test setup: data 
A major part of this thesis has focused on the evaluation and comparison of the developed prototypes.
The training and test data used for the comparison are domain-specific. 
The evaluation of the entity extraction and intent classification capabilities of the framework relies on the provided data sets.

% entity extraction
It was impossible to test the entity extraction capabilities of the frameworks unbiassed.
The person entity is unavailable for Watson Assistant, and LUIS had none for the German language.
The bias came from the creation of the entities since the training data quality is of different quality compared to the predefined ones.
An entity created by the developer might overfit or suffer from a small amount of training data.
This is a bias in the test setting since the performance is dependent on the training and test data provided by the developer and not on the technology alone.
With Watson Assistant, it was not possible to mark entities in the training sentences for the German language.
This rendered Watson Assistant useless for the German input language.
Watson Assistant provides no date span entity.
Two separate date entities were used instead to get the same result.
  
The Rasa framework does not offer any predefined entities itself and relies on other optional technologies like Spacy and Duckling.
Spacy offers date and date-span entities, but the result date is not in a standardized format.
The resulting dates are not machine-processable.
The automation criterion of chatbots requires dates in a standardized form.
To summarize, the date and date span entities of spacy were unsuitable.
This lead to the use of Duckling since it provided the necessary standardization for date and date-span entities out of the box.

Dialogflow offered two entities that can handle date-spans.
Both entities were tested to get the best result possible. 

The entities defined by the problem analysis of the user-cases are the person, date, and date-span entity.
The entity extraction test only included these three entities.

For the evaluation of the results, the recall, precision, and f-score values were used as \citet{braunEvaluatingNLU} did.
To calculate the values, the TP, FP, and FN values are counted for each individual test case.
The comparison of the frameworks has been difficult since some entities are not available using certain technologies.
Watson Assistant and Duckling had no person entity and LUIS had no person entity for the German language.
In the case of Dialogflow two entities were available that could be used for the date-span extraction.
The available enities were listed in Table \ref{tab:entity_extraction_recognition}.
To make the values comparable the result was calculated for each individual entity, the combination of date and date-span, and the combined score over across all entities.

% intent classification
The second major function of chatbots is the intent classification.
The intents were trained with the same utterances for all four technologies to create a fair test setup.
To measure the performance the precision, recall, and f-score values were used to provide an objective value.
As mentioned in Chapter \ref{chap:basics} Basics, the NLU services of all four frameworks provide a confidence value.
The confidence value is a response that represents how well the input fits an intent.
The result evaluation of this thesis has been extended with the confidence score since it indicates how good the training worked for the frameworks and if additional training data would have been necessary.
The additional value standard deviation was added to compare how consistent the chatbots' confidence scores were. 
The confidence scores were shown for the correct intent no matter if the intent was identified correctly or not to calculate and average confidence 
score across all tests.
The average confidence score provides another quality metric.
A high average confidence score combined with a high f-score indicates that the chatbot classifies intents reliably and vice versa.
A small standard deviation in combination with high average confidence indicates that the chatbot classifies intents reliably with a high confidence score. 
The intent classification was tested for English and German.
This was necessary since the 3 Banken IT has it's locations in Austria
which makes German the language of choice for potential users.
The expectation for the German tests was that there is no difference to the English tests which was not met since e.g. LUIS had no person entity for 
the German language.
The performance expectation was that the German bot is on the same level as the English bot regarding entity extraction and intent classification.

% implementation possible?
As \citet{singhbuilding} mentioned, the best evaluation criterion is if the underlying task can be achieved or not.
This evaluation criterion has been adopted for this thesis since it is the 
most relevant for a recommendation of a technology.
As a result, value for this evaluation, a binary boolean criterion was chosen.
Either it was possible to build a prototype that implemented the design or it was impossible.
The evaluation did not include an opinion or how hard the implementation was with a design.
Since LUIS is an NLU technology and not a chatbot technology it was excluded from this test because it offers no dialog handling mechanism.
It would have been unfair to include an NLU technology since it's not meant to handle dialogs.
The Microsoft Bot Framework uses LUIS and offers dialog handling but wasn't used in this thesis and is therefore not part of this test.

% speech recognition
For future project speech recognition capabilities are on the wish-list of the 3 Banken IT.
For this reason the speech-to-text and text-to-speech services offered for the 
chatbot technologies were compared based on their price.
Chatbots which offer speech functionality can be used through 
voice interfaces in the future.
The second evaluation criterion in the speech recognition category was
if speech services are offered by the provider. 
It was expected in general that each framework offers speech services for their chatbot technology since these are two closely tied topics.

% price comparison
A key factor for the use of chatbots is the price.
That the price plays an important role was mentioned in \citet{buiildChatbotsPython}, for instance.
None of the articles used for this thesis compared the prices of the 
available technologies.
The goal of the price comparison was to find out which technologies are cheap and which are expensive.
In combination with the other evaluations, the expectation was to find a cheap technology 
which performs well.
The price of a chatbot has been calculated for different categories since the prices were intransparent and hard to compare.
The first category was the price for the chatbot technologies, the second 
one eas the price for hosting, and the third category was the price 
for speech-to-text and text-to-speech services.
The prices for the chatbot technology for the enterprise edition of Rasa 
and Watson Assistant is not listed on the website since it's calculated 
individually.
The prices for the Microsoft Bot Framework were calculated by adding the price for the Microsoft Bot Framework and LUIS.
The prices for Watson Assistant are calculated per user per month while the price for Dialogflow, LUIS, and the Microsoft Bot Framework was based on the number of requests.
Rasa is free by default and was excluded from the price calculation since 
no prices were listed on the website.
The prices for the text-to-speech and speech-to-text services were comparable for Watson Assistant, Microsoft Speech Services, and Dialogflow.
Rasa didn't offer text-to-speech and speech-to-text services at all.
The general expectation was that the frameworks cost roughly the same but the prices were hard to compare or not comparable at all.

% portability 
Another evaluation criterion used for this thesis is the portability of software systems, as defined in the ISO 25010\cite{iso25010} standard.
The portability was chosen since the comparison of the cloud 
technologies with a local technology was interesting from a 
development point of view.
The first factor discussed in this thesis were the necessary tools 
since they determine how portable the development environment of the 
chatbots are.

%% local vs cloud
The portability of the development environment of the local technology 
Rasa in contrast to the cloud chatbot technologies was the 
main focus of this evaluation.
The second factor chosen was the number of providers where the 
chatbot can be deployed.
The main focus lay on cloud technologies since the expectation was
that they can only run in the environment of the provider and are 
not portable at all.
The third portability category chosen was how flexible the development
of chatbots is regarding the devices.
The expectation was that cloud technologies are developed in a 
web browser and can be developed from almost anywhere while 
the local technology requires a development environment and is 
comparably unflexible.

%% migration
Another aspect of portability is the migration from one technology to another.
It was expected that all technologies safe the data differently and that it's not easy to migrate between them.
% project setup
For the development of a chatbot, the project setup complexity plays an important role and was evaluated in this thesis.
The main focus of this test was Rasa since the setup complexity was interesting for the local technology.
The setup of the cloud technologies was expected to be easy since the providers take care of the setup for the customers.
% deployment complexity
The deployment of chatbot systems is an important aspect when local and cloud technologies are compared.
While it was expected that a cloud technology produces no deployment overhead the opposite is expected for a local technology since the deployment needs to 
be done by the developer.
For the local technology, the Docker deployment and setup of a local Python environment were included in the evaluation.
Especially the deployment using Docker has proven as interesting for 
future projects because of the flexibility and simplicity. 
% learnability
The ISO 25010\cite{iso25010} defines learnability as sub-criterion of usability as measurement metric for software systems.
The learnability is important from a development perspective since an easy to learn and use technology is the optimal case when the performance is good.
The evaluation of the project setup and deployment complexity was included in the learnability since they are part of the development of a system.

%% predefined entities
As mentioned before, the chatbot technologies use entity extraction to extract data from text.
The entity extraction is a part of the development process of a chatbot
and it takes time to define good entities.
All of the chatbot technologies offer predefined entities that are ready to use.
As a criterion, the number of predefined entities was defined as a measure since lots of predefined entities can save lots of development time for future projects.
If a required entity is available for a given problem the developer doesn't need to create one.
The second measurement criterion it the entity category is if the chatbot technology predefined all required entities for the use-cases of this thesis.
The technologies where all required entities were predefined are better suitable to solve the given problem.
It was also evaluated how hard it is to create new intents, entities, training phrases, and dialogs.
The expectation was that it is equally complicated for each technology.

%% design of conversations, nodes, and stories
As mentioned by \citet{folstad2017chatbots} the design of chatbots is all about the conversation.
Hence, the most important aspect was the creation of dialogs.
The frameworks Dialogflow and Watson Assistant offered dialog nodes 
to create and structure conversations.
A dialog node is one step of the conversation and can be followed by another dialog node.
A dialog node was e.g. the classification of the sickness notification intent
followed by the collection of the name and return date to the response of the system.
Rasa offered stories to represent a dialog.
A story represents a whole conversation path from start to finish.
The start was a greeting line and the end the goodbye response for instance.

%% form data
An important part of the conversations required for this thesis was the 
extraction of form data and has been evaluated regarding the 
complexity.
Rasa was the only technology tested where programming skills were necessary to extract form data from the conversation. 

% customization possibilities
%% pipeline: custom components
For developers, an important factor are the customization possibilities.
It is an advantage for when the pipeline can be fine-tuned to increase the 
performance or add special custom components.
The only tested framework which offered pipeline customization was Rasa.
A developer can even create new custom components and include them in the pipeline. 
This is interesting for very specific company requirements, research, and fine tuning to increase performance.
The other tested technologies didn't even display the configuration of the pipeline.
When Rasa is used for development the pipeline is adjustable to the 
developers needs.
For the development of the prototype with Rasa the technologies Spacy and Duckling were added to the pipeline for entity extraction.
This was not possible with the other frameworks since the pipeline can't 
be adjusted at all.

%% story vs dialog node
The stories used by Rasa were adjustable fine granular compared to the dialog node approach of Dialogflow and Watson Assistant.
A story could be used to execute multiple actions and display multiple responses in a row.
Watson Assistant can't execute multiple actions but can call the webhook where the request can be processed.
Dialogflow can't execute multiple actions or display multiple responses. 

%% action server VS regular form data
With Rasa, the default form action was implemented using Python while no programming skills were required for form actions using Watson Assistant and Dialogflow.
The advantage of a programming language for form actions is that the concepts of a programming language are available for the validation of entries and calling external services.
Hence, a comparison of the programming based approach with the cloud approach was included in this thesis.

% framework concepts
%% intents, entities, utterances
As discussed in Chapter \ref{chap:basics} Basics, the concepts used by the frameworks are interesting.
The base concepts intent, entity, and utterance are present in literature and it was expected that these concepts are also present in the frameworks.

% communication
Another important aspect is the communication with the chatbot services.
%% JSON format
In general, JSON is the request and response format for all tested technologies.
All the technologies offered a REST interface for communication.
%% meta info
The messages differed when the content was compared since 
LUIS and Dialogflow sent metadata while Watson Assistant and Rasa did not.
These are two very different approaches which were evaluated for 
positive and negative aspects.
The meta-information can be used in the backend for future projects to 
create e.g. statistics.

% process external information
The communication can also be seen from the other side when a service sends additional information to the chatbot.
It was evaluated how easy it was to process additional information
in a chatbot.
The expected result was that Rasa is the easiest technology for processing information since it is the only technology which uses a programming language for data processing.

% training capabilities
Another big difference between Rasa and the other technologies were the 
training capabilities.
%% live training
Live training is offered by Rasa while all the other technologies 
were solely trained with the training data defined by the developer.
When live training is used the created stories are expected to be closer 
to a real-life scenario because the developer has to go through the conversation step by step.
This can prevent unnatural conversations since the developer creates the conversation step by step.
% user interface design
In the ISO 25012\cite{iso25010} defines the user interface aesthetics under the section usability. 
Hence the user interfaces of the frameworks were also compared regarding simplicity.
%% how simple, how easy to orient
This was evaluated from a subjective point of view.
The interface of a framework was evaluated as easy to use when the overall structuring was easy to understand and the prototype was easy to implement.


\section{Course of Action} % Ablauf
After the problem had been analyzed the dialog flow-chart was 
created.
Based on the flow-chart, the required intents and entities were defined.
The required intents are sickness notification and vacation request.
For each use-case, one intent was necessary.
The conversation built in the flow-chart made the required entities visible.
For the sickness notification the name of a person and an optional 
return date were required.
The vacation request needed the name of the person and a date-span.
The resulting entities were person, date, and date-span.
For each intent, 10 training sentences were created in English and 
10 were created in German.
The test sentences were used to develop a German and English prototype 
with each technology.
For the entities and intents, test sentences were defined.
The entity test sentences were evaluated as TP, FP, TN, and FN.
Based on these values the precision, recall, and f-score was calculated 
to provide an objective evaluation.
The same approach was used for the evaluation of the intent classification plus the additional properties for the confidence and standard deviation.
For each test category as summary was created to compare the 
performance of the technology for each category.
The frameworks were evaluated based on the criteria listed in 
Section \ref{sec:comparison_and_eval}.
The results were used to rank the frameworks in different categories 
which show the strengths and weaknesses to make a final recommendation for further projects.
Furthermore, the entity extraction and intent classification results in 
English and German show which technology performed best in the 
given domain.