% Hybrid coding networks
There are many ways for chatbot type classification, and the category selection depends on the developer or researcher's view and needs.
\citet{williams2017hybrid} and \citet{bordes2016learning} state that the two major chatbot types are goal-oriented and end-to-end systems.
These two classes define the general type of conversation.
% Kane 2016 role of chatbots in teaching and learning
Another way of classification is the differentiation between local standalone-applications and web-based solutions like done by \citet{kane2016role}.
These two categories define the type of development, the source code's location, and the usage type of a chatbot.

The types/classes of chatbots from \citet{williams2017hybrid, bordes2016learning} and \citet{kane2016role} don't contradict they just look at chatbots from a different perspective.
From the design perspective, the conversation type of a chatbot is either goal-oriented or end-to-end.
From the development perspective, the used framework is either web-based or local.
A combination of these categories is possible as Rasa is an example of a local standalone application built for goal-oriented dialog.
The web-based solutions LUIS, Dialogflow, and Watson Assistant, use goal-oriented dialog.

% ---------- BASICS/CONCEPTS ---------- %
% deshpande 2017 survey
Current chatbot systems use natural language processing (NLP) to respond to user inputs \cite{deshpande2017survey}.
\citet{deshpande2017survey} shows the evolution of chatbots from the first chatbots to current state-of-the-art chatbots like Alexa and Siri.
The first chatbots created used pattern matching to respond to users, whereas current technologies like Siri use NLP.

The analysis of questions and statements is the main focus of NLP in the area of chatbots \cite{deshpande2017survey}.
Extraction intents, commands, and actions from user input is the goal.
The basic workflow of a chatbot system starts with the user input. 
Then the NLP engine extracts entities and detects the intent.
An entity represents an interesting piece of information.
The extracted data is store in entity slots.
After the extraction, the user gets a response from the chatbot.

% Building chatbots with Python
Some of the best chatbot and NLP frameworks are Rasa, LUIS, and Dialogflow \cite{buiildChatbotsPython}.
\citet{buiildChatbotsPython} used Dialogflow to build a classical food order chatbot and Dialogflow to build a horoscope bot.
To summarize, \citet{buiildChatbotsPython} recommended Rasa, LUIS, and Dialogflow and used two of them for the implementation of chatbots.
The collection of state-of-the-art technologies is an important task of this thesis, and these three are candidates.

\citet{buiildChatbotsPython} is an excellent source to learn about the core concepts of chatbots, NLU, and NLP necessary for the development of chatbots.
Chatbots do not require complex interfaces since they support natural language.
The interaction with a chatbot is natural and easy, and they get more and more popular.
They often seem intelligent, but developers and users should be aware that chatbots cannot do everything and often serve one specific task.
Such bots fall under the task-oriented category.

A core question before the development of a bot is if the underlying problem is suitable for a chatbot or not \cite{buiildChatbotsPython}.
Three factors determine if the problem is suitable for using a chatbot.
Analyzing the problem is necessary to answer the question.
Chatbots use simple back back-and-forth communication.
No other means of communication are available.
Hence, a suitable problem requires only simple back-and-forth communication to achieve its task.
A suitable problem is also highly repetitive and automatable.
It does not make much sense to implement a chatbot for a non-repetitive task, which cannot be automated.
The development overhead for non-repetitive tasks is not worth the effort from a financial perspective.
Non-automatable tasks require human help to be done, which is what a chatbot should get rid of in most cases.
A suitable problem for a chatbot solution is a FAQ help page, for instance.
The problem is repetitive since users query a predefined set of questions and answers.
The FAQ page is automatable since the user communicates solely with the web-page without human help.
The problem scope consists only of questions and answers.
This fits the required back-and-forth communication pattern perfectly.
The FAQ page is suitable since all three required factors are present.


% Geyer 2016 named entity recognition in 140 chars or less
Named entity recognition (NER) is the core concept used by chatbot tools to extract information from text \cite{geyer2016named}.
The classic examples of named entities are people, locations, and organizations.
An important quality factor of NER systems is how good the entity extraction works.
The frequency of entities in the training data can influence the NER performance significantly. 
Since entity extraction is one of the core concepts of chatbots, a similar evaluation is possible for chatbots.

% IEEE: Rahman 2017 programming
Commonly used cloud chatbot solutions are IBM Watson, Dialogflow, and the Microsoft Bot Framework \cite{rahman2017programming}.
Tech giants provide chatbot frameworks for regular developers where programming and ML skills are no longer required.
Google provides API.ai/Dialogflow, Microsoft has LUIS, IBM develops Watson, and Amazon provides Lex.
Goal-oriented chatbots are most common in the business sector and help users to achieve tasks.

In general, the chatbot architecture consists of intent classification, entity recognition, response generator, and a response selector  \cite{rahman2017programming}. 
The intent classification identifies the best matching intent for the user input.
The entity recognition module extracts the information/data from the user's message.
The response generator provides response candidates, and the response selector chooses the best matching response.
The core concepts used by Dialogflow are intent, entity, and utterance.
Intents execute actions based on the user's input. 

The state-of-the-art technologies mentioned by \citet{rahman2017programming} are IBM Watson, Dialogflow, the Microsoft Bot Framework, and Amazon LEX.

% ---------- EVAL ---------- %
To summatize, \citet{deshpande2017survey,buiildChatbotsPython,geyer2016named} and \citet{rahman2017programming} focus on the basics of chatbot frameworks and chatbot related concepts.
\citet{deshpande2017survey} and \citet{rahman2017programming} describe the general workflow of chatbot systems.
\citet{geyer2016named} is about NER which is one of the core concepts used by chatbot systems.
Additionally, \citet{buiildChatbotsPython} also explains which problems are suitable for a chatbot in general.
% ---------- END BASICS/CONCEPTS ---------- %

End-to-end systems for general conversations are the first major chatbot type.
% ---------- END-TO-END SYSTEMS ---------- %
% evaluate chatbots Shawar
\citet{evaluateChatbotsShawar2007} focuses on the application of chat systems in different languages and the evaluation of chatbot systems in general.

The best way to evaluate a chatbot is to check if the specific service or task is achievable \cite{evaluateChatbotsShawar2007}
The evaluation of chatbot systems depends on the use-case, the application, and the user's needs.
A conventional test approach is a system test to acquire user feedback.
This helps to evaluate user satisfaction and acceptance.
The feedback is used to improve the system.
It is also possible to test the components of a chatbot system individually.

Custom-built solutions can outperform classical approaches in small areas \cite{evaluateChatbotsShawar2007}.
\citet{evaluateChatbotsShawar2007} built a chatbot for frequently asked questions (FAQ).
The custom FAQ bot competed against the classical Google search.
The participants had to answer a few questions like how many results the system found, which system they preferred, and why. 
The custom solution found a reasonable answer in more cases than Google search.
47\% of the users taking part in the study preferred the custom solution, and 11\% preferred Google.
The primary reason why the users preferred the FAQ chat was because the chat can often give direct answers and returns fewer links on average, which saves browsing time. 
The users preferred Google because it is familiar, and it can give different answers when the input query is adjusted slightly.

% Bordes 2016 learning goal-oriented dialog
\citet{bordes2016learning} analyses the strengths and weaknesses of end-to-end dialog systems in goal-oriented settings.
The end-to-end approaches have recently shown promising results with chit-chat/general conversation with a user.
However, The most useful application areas for chatbots are either goal-oriented or transactional settings.

A classical dialog system uses slot-filling to collect information from the conversation \cite{bordes2016learning}.
Slot-filling is reliable but has limited scalability.
The slots are predefined and hence do not scale well because they can be different for each problem. 

The main question is if end-to-end systems perform well on the classical goal-oriented restaurant reservation task \cite{bordes2016learning}.
End-to-end systems scale well because they learn directly from conversations and make no assumptions regarding the domain or dialog structure. 
The restaurant reservation is a domain where goal-oriented systems perform well and is the ideal candidate to determine the strengths and weaknesses of end-to-end systems in goal-oriented settings.
The results of \citet{bordes2016learning} show that end-to-end systems are not yet ready to replace goal-oriented systems and have to improve before they can perform reliably in goal-oriented settings. 

\citet{bordes2016learning} compared the chatbot types based on the number of correctly identified requests (true positives) and the number of dialogs where every request was identified correctly.
Multiple conversations were used to test the system, but the end-to-end system never identified all requests of the conversation correctly \cite{bordes2016learning}.
The request identification worked well, but no conversation went smoothly since at least one request was identified incorrectly.
In other words, each user had at least one problem in the conversation.
This would lead to a bad user experience. 
In summary, the most important statement of \citet{bordes2016learning} is that the current end-to-end systems are not performing reliably enough in goal-oriented settings.

% Williams hybrid coding
\citet{williams2017hybrid} introduces an approach that combines end-to-end dialog with domain-specific knowledge.
A task-oriented system helps the user to achieve a task using natural language.
A restaurant reservation is a task-oriented operation that requires domain-specific knowledge.
The domain-specific knowledge in a restaurant setting can be the restaurant name and the number of people for the table reservation, for instance. 

End-to-end systems lack a mechanism to inject such domain-specific information \cite{williams2017hybrid}.
The extraction of such information is required to perform well in a goal-oriented setting.
There is also no mechanism for constraints in goal-oriented systems.
In a banking app, the user needs to log in (constraint) before retrieving account information.
A programmer can code such constraints in a few lines, but lots of training data need to be provided to a system to learn such a mechanism on its own.

The hybrid-coding-networks (HCNs) approach extends the open-ended system with domain-specific knowledge \cite{williams2017hybrid}. 
The programmer provides the domain-specific knowledge to the system, which results in more development effort.
Since the domain-specific knowledge is provided, the system does not need to learn these parts, and less training data is required compared to existing end-to-end approaches.
Real dialogs provide a large source of training data.

The experiments show that the HCN approach performs on an equal level with existing end-to-end approaches in end-to-end settings and need less training data to achieve the same performance \cite{williams2017hybrid}. 
The HCN system also performed better in the task-specific setting than the existing end-to-end approaches.
The developer has more control than with the classical end-to-end approach, but it also requires more development effort to create a chatbot with HCNs.
The main benefits are domain-specific information in an end-to-end dialog and the reduced amount of training data.

Other references focus on end-to-end and goal-oriented chatbots, whereas \citet{williams2017hybrid} combined them to get the best of both worlds.
\citet{williams2017hybrid} does not compare the HCN approach to a goal-oriented approach like \citet{bordes2016learning} did for regular end-to-end systems.
Hence, it is impossible to make a statement if HCNs could replace goal-oriented systems or not.

% ---------- EVAL ---------- %
In \citet{evaluateChatbotsShawar2007} testing focus lies on the user side whereas the testing focus of \citet{braunEvaluatingNLU} lies on the NLU capabilities.
The NLU capabilities are an important factor before a chatbot is developed and help to choose the best framework for development.
The user's feedback is a valuable source of information for the actual product and is important long after the framework was chosen.
These are two very different views on the performance of a chatbot in two different phases of a project.

\citet{bordes2016learning} focuses on end-to-end systems like \citet{evaluateChatbotsShawar2007}, and \citet{williams2017hybrid} but uses a goal-oriented setting for the comparison.
The important information gained by \citet{bordes2016learning} is that currently, end-to-end systems are not reliable enough for goal-oriented tasks.
Since goal-oriented technologies are the only ones that perform reliably in goal-oriented settings, using them for goal-oriented projects is recommended.

\citet{williams2017hybrid} combines the end-to-end and goal-oriented approaches to create a new type of system which can do goal-oriented dialog better than current end-to-end approaches. 
The HCN comparison does not include goal-oriented approaches, which makes the result irrelevant for this thesis.
% ---------- END END-TO-END SYSTEMS---------- %

% ---------- BOTH SYSTEMS---------- %
% singh building: building an enterprise chatbot
The conversation type of a chatbot is wither a general conversation about a broad generic subject or a specific conversation about one product or service \citet{singhbuilding}.
The first step to create a chatbot system is to define a conversational flow.
The conversational flow is a decision tree that describes the possible events, decisions, and outcomes of a conversation.
An example of a general conversation is when a customer walks into a bank and starts talking to an employee.
In this example, we have no idea what the person wants or who the person is.
Famous examples of chatbots capable of general conversation are Google Home, Siri, and Amazon Alexa.

An example of a specific conversation is the refund desk in a store \cite{singhbuilding}. 
Specific rules apply to the refund process, and specific information is required from the customer.
The domain could be named refund, and the specific rules and information are part of the domain. 
The customer cannot get any other information than refund related information at the refund desk. 
The conversation's outcome can be one of the predefined outcomes, the fallback, or a conversation end. 
A specific conversation ends as soon as the underlying task is achieved or a conversation end is reached. 
In general, specific conversations are easier to predict and are handled with higher accuracy.

The core component of AI-driven chatbots is the NLP engine, which takes care of data extraction from natural language \cite{singhbuilding}.
The extracted information determines the next steps.
There is no difference in functionality between a regular application and a chatbot in terms of functionality. 
The difference is that a chatbot uses conversation, whereas a regular app is a self-service application. 
Conversational training data for chatbots can be acquired from lots of sources like emails, phone calls, chats, and social media.

Companies use chatbots because they can save much money and offer a good customer experience, but there are also security issues for cloud solutions \cite{singhbuilding}.
Especially in areas with personal data, cloud chatbot solutions like Dialogflow, Alexa, and Watson are problematic because all the conversation data is sent to and stored at the providers' server.
Local chatbot solutions like Rasa are an option for applications whit high-security requirements.
\citet{singhbuilding} built an in-house/local chatbot to provide the required security.

\citet{singhbuilding} also gives an overview of the basics of Microsoft Bot (LUIS), Rasa, and Google Dialogflow.
Furthermore, \citet{singhbuilding} mentions Alexa, Google Home, and Siri as popular natural language systems. 
The second big chatbot category is called goal-oriented.
% ---------- BOTH SYSTEMS---------- %


% ---------- GOAL-ORIENTED SYSTEMS ---------- %
% Braun evaluating NLU
Modern conversational agents require small to no programming knowledge because of NLU services \cite{braunEvaluatingNLU}. 
The recent advancements in machine learning (ML) and NLU and the popularity of messenger platforms has led to huge progress in recent years. 
Many people use messenger platforms daily, and most are familiar with such platforms.
Hence, chatting has become a natural way of communication.

In general, The architecture of a chatbot consists of the request interpretation, the response retrieval, and the response message generation \cite{braunEvaluatingNLU}.
The purpose of these services is the extraction of information from natural language. 

Popular NLU services are the cloud services LUIS, Watson Conversation, Dialogflow/API.ai, and RASA as an open-source alternative \cite{braunEvaluatingNLU}. 
The cloud-based solutions have advantages when it comes to hosting and scalability, and Rasa has advantages when adaptability and data control are needed. 
All three NLU services share the same basic concepts of intents, entities, and batch import in JSON format.
The cloud-based services are secretive when it comes to the ML algorithms and the initial training data. 
The exception is Rasa, where the developer chooses and modifies the ML backend. 

Recent publications discussed the use of NLU services but did not mention why one service was chosen over another \cite{braunEvaluatingNLU}.
\citet{braunEvaluatingNLU} used training data from a production chatbot and two other training sets from StackExchange to evaluate the performance of the NLU services.
The comparison included the services LUIS, Rasa, Dialogflow, and Watson Conversation.
The services use the same training data to create a fair testing environment. 
The evaluation of the services NLU capability uses true and false positives and negatives, recall, precision, and F-score. 
The better the F-score is, the better the NLU service has performed. 
The evaluation of NLU services is only a snapshot since the services are continuously improving. 

LUIS performed best on all datasets, but in the area of chatbots, Rasa and LUIS performed on an equal level \cite{braunEvaluatingNLU}.
Rasa can be customized further than LUIS and could outperform LUIS through customization. 
The domain had little to no influence on the ranking of the NLU performance.
In other words, a good NLU system performs good independent of the domain.
If the training data is sparse, there is no significant difference between the services' performance. 
Before using an NLU service, different services should be tested with domain-specific data to find the best matching technology for the given problem.

The comparison and evaluation of \citet{braunEvaluatingNLU} included LUIS, Watson Conversation, Dialogflow/API.ai, and RASA.
These four technologies are used and mentioned in many articles and online sources. 

% Dutta 2017 developing
In \citet{dutta2017developing}, a chatbot is developed that assists high school students with learning general knowledge subjects and analyses the impact the chatbot had on the learning process.
The developed chatbot is a web-based education solution using natural language processing (NLP) techniques to answer questions.
The bot can participate in small talk to create the illusion of talking to a human.
It also helps to motivate learners and might increase interest in the topic.

Popular chatbot platforms are Dialogflow, LUIS, Wit.ai, and Pandorabots \cite{dutta2017developing}.
The chatbot systems evaluation is based on their NLP performance and the available features of the platform
The training data is the same for all technologies to make a comparison possible. 
LUIS and Wit.ai showed a slightly better NLP performance than Dialogflow.
Dialogflow offers the concept of follow-up intents, which is an important feature for the development of sub-tasks.
Thus, Dialogflow was chosen for development over LUIS and Wit.ai.
Use-cases for AI-based chatbots are banking systems, customer services, and education, for instance.

\citet{dutta2017developing} uses goal-oriented technologies like \citet{braunEvaluatingNLU} and both compare the technologies based on their NLU capabilities.
Additionally, \citet{dutta2017developing} also focuses on the platforms' available features and selects Dialogflow over the other technologies because of these features.
\citet{dutta2017developing} also touches the psychological aspects of chatbot systems like the motivation of users through small talk. 
\citet{GO2019304, brandtzaeg2018chatbots}, and \citet{folstad2017chatbots} go deeper into the psychological aspects of chatbot systems.

% Gregori 2017 evaluation
The higher the confidence score is, the better the user request matched the training data \cite{gregori2017evaluation}.
\citet{gregori2017evaluation} evaluated the NLU capabilities of Wit.ai, Luis, Api.ai/Dialogflow, and Amazon Lex\cite{lexconversational}
by the confidence score. 
As other researchers already mentioned, each tool was trained with the same data and was tested with the same questions to ensure fair conditions.
LUIS, Wit.ai, and API.ai/Dialogflow performed on an equal level in terms of intent classification.
\citet{gregori2017evaluation} is another researcher that chose Api.ai/Dialogflow for the development of a prototype.
It seems that many researchers use Dialogflow for the development of a chatbot.

% IEEE: pharmacy bot
\citet{pharmacybot} builds a chatbot to aid customers with questions regarding medication for a pharmacy company using IBM Watson.
The bot can provide medications for an illness, give information about a specific medicine, and give information on the medication intake.
The bot is a domain-specific bot since it answers questions to medication only.

% In bot, we trust:
Important performance metrics for chatbots are the conversation length and structure, the ability to provide personalized communication, and the number of conversation steps \cite{PRZEGALINSKA2019785}.
In general, the measurement criteria for chatbots vary depending on the domain of the bot.
The general trend is to keep conversations short.
Personalized communication is used when recommendations or tips are provided for the user based on the information related to the user.
Retail chatbots need a larger amount of conversation steps to provide information and recommendations and hold the user's attention.

% Luis 2015 Williams
Historically, language understanding was implemented via machine learning or handcrafted rules \cite{luis2015williams}.
\citet{luis2015williams} gives an overview of LUIS, the state-of-the-art language understanding service of Microsoft.
The ML model approach is robust but requires expensive expertise. 
In general, software developers can build language understanding without the assistance of a framework with handcrafted rules.
However, systems with handcrafted rules do not scale well.

Using LUIS, developers do not need machine learning knowledge to build language understanding models, nor do they need to write handcrafted rules \cite{luis2015williams}.
LUIS allows regular developers without ML expertise to develop a cloud-based, domain-specific language understanding models.
Developers need to understand the concepts' intent, entity, and utterance to work with LUIS.
Developers can create custom entities and use existing entities like location, date, and time.
LUIS offers an HTTP endpoint using JSON format for messages.
Dialogflow, Rasa, and Watson Assistant also use HTTP endpoints for communication and JSON format for the messages. 

% rasa bocklisch 2017
Rasa is an open-source tool for natural language understanding and dialog management built for developers \cite{rasabocklisch2017}.
Rasa uses the concepts of intent and entity. 
The cloud chatbot technologies have these two concepts in common with Rasa.
Slots and events represent the state, and the state stores the events which led to the current state. 
The tracker stores the state information.
An action has access to the tracker and determines the next step to take. 
An action can be something simple like an utterance or something complex, like the execution of a function.

Rasa consists of a natural language and a dialog component accessible via an HTTP API \cite{rasabocklisch2017}.
The format of Rasas training data is either JSON or markdown and is chosen by the developer.
Rasa supports live training of the system where the developer can correct the bot while communicating with it.
Live training is an effective way to create training data for plausible conversations.
With live training, there is a higher possibility of creating a complete and natural conversation because the developer is forced to go through the conversation step by step.


% ---------- EVAL ---------- %
\citet{braunEvaluatingNLU} compares some NLU frameworks regarding their natural language capabilities.
The result of \citet{braunEvaluatingNLU} showed that Rasa performs on an equal level with tools like LUIS.
The compared frameworks are suitable for task-specific problems.
\citet{evaluateChatbotsShawar2007,bordes2016learning} and \citet{williams2017hybrid} focus on end-to-end systems while \citet{braunEvaluatingNLU, dutta2017developing,luis2015williams,rasabocklisch2017,pharmacybot} and \citet{gregori2017evaluation} focus on task-oriented systems, and \citet{singhbuilding} is about both.
\citet{singhbuilding} gives a general overview of the chatbot types, gives development advice, and introduces popular chatbot technologies and their basics.
\citet{braunEvaluatingNLU} gives an overview of the architecture of chatbot systems and evaluates the NLU capabilities of chatbot frameworks.
\citet{gregori2017evaluation} and \citet{dutta2017developing} give no arhcitecture overview but evaluate the NLU capabilities.

When comparing the frameworks NLU capabilities, the same training data needs to be used for all tested frameworks like done by citet{braunEvaluatingNLU} and \citet{gregori2017evaluation}.
\citet{dutta2017developing} also introduces a framework comparison based on the available features and some psychological aspects of chatbot communication.
Unlike other references which either use or evaluate frameworks, \citet{luis2015williams} and \citet{rasabocklisch2017} 
introduce the frameworks LUIS\cite{luis2015williams} and Rasa\cite{rasabocklisch2017}. 
They focus on the technology itself and do not build a chatbot with it, nor do they compare frameworks.
\citet{dutta2017developing, pharmacybo}, and \citet{PRZEGALINSKA2019785} developed actual chatbots for specific use cases.
Common chatbot technologies found in the articles and books are Dialogflow, LUIS,  Rasa, Watson, and Wit.ai.
Many researchers use, mention, and compare those four chatbot technologies, and they are considered state-of-the-art for this thesis.
% ---------- END GOAL-ORIENTED SYSTEMS ---------- %

% ---------- DESIGN PSYCHO ASPECTS ---------- %
% folstad 2017 chatbots and the new world of HCI
Chatbots can also be viewed from a psychological perspective that focuses on user interaction \citet{folstad2017chatbots}.
\citet{folstad2017chatbots} investigates how users are communicating on the web and shows how the recent technological advances in the area of chatbots could influence the human-computer interaction in the future.
Many people are already using natural language as the primary input method on the web through mobile messengers and social networks. 

At the moment, the natural language conversation online is from human to human through a machine interface \cite{folstad2017chatbots}.
The people are using messenger platforms (machine-interface) to communicate with other people (human to human).
At platforms like Twitter, machine agents can already be integrated and communicate with human users.
The prime example of state-of-the-art conversational interfaces is Google Assistant.
 
Chatbots are different from classical software interfaces because they use natural language for communication instead of a classical GUI \citet{folstad2017chatbots}.
Currently, developers focus on the design of user interfaces.
The design focus for chatbot systems lies in the conversation, which is an entirely different approach than developers are used to at the moment.

Regular UI systems are designed by experts and improved by qualitative data, which is rather sparse \cite{folstad2017chatbots}.
A big advantage of conversational interfaces is the massive amount of training data present around the web. 
Chatbots all use messenger like interfaces independent from the problem.
This means that developers need to switch to a goal-oriented view where the main focus lies on understanding what the user wants and how they can be served.

% Brandtzaeg 2018 chatbots: Changing user needs and motivation
Chatbots are natural language interface using text or voice for communication \citet{brandtzaeg2018chatbots}.
They are used to retrieve content or access a service through natural language conversation.
Nowadays, people are used to natural language communication because they spend lots of time on messenger platforms.
Because of this, chatbot technologies become more and more popular.
\citet{brandtzaeg2018chatbots} focuses on the psychological aspects of chatbot design and gives recommendations independent from the type of chatbot.

It is challenging to design chatbots for open-ended conversations because users can start the conversation in many ways \cite{brandtzaeg2018chatbots}.
As an example, person to person communication is like the open-ended chatbot approach.
The conversation can develop in any direction, and there is no specific topic given.

It is vital to balance the human and robot aspects of a chatbot to keep the conversation as natural as possible \cite{brandtzaeg2018chatbots}.
If the chatbot feels too human, people might ask questions unrelated to the domain.
If it is too robot-like, people might complain because the conversation feels unnatural and robotic.
Developers also need to think about how friendly a chatbot should be, how fast the bot should answer, if the bot should have a gender, and how human-like the bot should be in general.

Successful chatbots inform the users what they have to expect and clarify that they are talking to a bot right from the start \cite{brandtzaeg2018chatbots}
Chatbots should inform users about what they can do, and it can help to inform them about what they cannot do.
Three examples for commercial chatbots are Microsofts Heston Bot for food, cooking opportunities and fashion, H\&Ms bot for shopping suggestions based on photos, and Ikeas shopping assistant bot.
Such conversational interfaces need to be improved based on interactions with humans and their feedback.


% humanize bots 2019
The main functions of current online chatbots are interaction with users, address of concerns, and question answering \cite{GO2019304}.
These chatbots often lack humanness when communicating with users.
The impersonal nature of the conversation can be countered with a high level of message interactivity.
\citet{GO2019304} is, in general, about human-like bots and the effects they have on users and compares these bots with current chatbot systems.

There are three approaches to increase the humanness of chatbots \cite{GO2019304}.
The humanness is increasable through visual cues like human figures, identity cues like a human-associated name, or conversational cues by mimicking the human language.
Introducing visual cues and a name to a chatbot is an easy task.
Conversational cues are hard to create since they require a deep understanding of the human conversation and the context.
These three approaches can be used to make people believe that they are talking to a human or a bot.

The user interaction and expectations change significantly through the user's assumption, as mentioned by \cite{sundar2016theoretical} and \citet{GO2019304}.
If a user expects a human agent, then the chatbot is more likely evaluated as human-like, and the conversation feels more natural for users than when they expect a bot.
If the bot is identified as a human, the users automatically expect more from the conversation.
The bot needs to be capable of more, or the users will be disappointed.
If the bot is identified as a bot, the users expect less from the conversation.
The downside is that the conversation is more likely evaluated as robotic or unnatural.
This needs to be kept in mind when designing chatbots since false identification as a human can lead to a huge decrease in user satisfaction and acceptance.
The user assumption (bot or human) has a high impact on the chatbot evaluation and feedback.

% ---------- EVAL ---------- %
Unlike the other references \citet{folstad2017chatbots, brandtzaeg2018chatbots} and \citet{GO2019304} focus on the psychological aspects of chatbots and the communication with machines in general.
\citet{GO2019304} is about the humanness of bots.
It is important to keep in mind how human a bot should be and how the user assumption influences the feedback.
If the bot appears to be human, the expectations rise.
If the bot is presented as bot right from the start, the expectations are lower.

\citet{brandtzaeg2018chatbots} also focuses on the psychological aspects and the humanness of bots.
The disadvantages of too human bots are listed with real-life examples. 
Real chatbot conversations have shown that users ask unrelated and inappropriate questions if a chatbot is too human. 
Hence, it is crucial to balance the robot and human aspects when designing a bot \cite{brandtzaeg2018chatbots}.

\citet{dutta2017developing} is about chatbot design aspects.
The important message of \citet{dutta2017developing} is that chatbot systems are entirely different from conventional systems from the design perspective.
Right now, developers focus on the design of user interfaces (UIs).
This approach does not work for chatbots since they all have the same UI requirements independent from the use case.
They either use messenger like UIs for text communication or no UI at all through speech interfaces.
This means that the design focus of a chatbot is not the UI.
It is the conversation.
Hence, the main design focus needs to shift from UI design to conversation design.
% ---------- END DESIGN PSYCHO ASPECTS ---------- %

% ---------- EXAMPLES ---------- %

% ---------- END EXAMPLES ---------- %


% ISO 25010
ISO/IEC 25010 defines quality characteristics for the evaluation of software systems \cite{iso25010}.
Functional suitability is split into functional completeness, correctness, and appropriateness.
There are also performance efficiency metrics to check the time behavior of a system with the throughput time.
The interoperability of systems can be verified by checking the exchanged information.
Usability can be checked through learnability, which determines how easy it is to learn to use the product.
Security can be checked by checking for unauthorized access problems.
A part of portability is how easy it is to install a system.
ISO/IEC 25010 provides evaluation criteria for software systems that can be used to evaluate chatbot systems.


% my conclusion
The researchers in the literature used for this thesis mainly focus on introducing new approaches or comparing different types of chatbots.
Some researchers compare chatbots regarding NLP and ML performance.
In most cases, the actual frameworks are not compared regarding, e.g., offered features, learnability, and the price.
Most papers focus on NLP capabilities and ignore other aspects like usability, simplicity, or the comparison of the different frameworks' functionality.
Nor is the ISO 25010\cite{iso25010} used, which is a standard for the evaluation of software systems.
A major point of this thesis is the recommendation of a framework for future developers and projects in the 3 Banken IT.
For this reason, aspects like learnability are considered because they are relevant for developers.
Aspects like the costs are essential for companies, but researchers do not address this issue.

Resources like \citet{braunEvaluatingNLU} show that the differences between chatbot frameworks are small when it comes to NLU performance.
Hence, the impact of the framework on the NLU performance of the system is rather small.
The NLU capabilities of the framework are important in general. 
However, to give a development recommendation, other aspects like the available features and the simplicity of a framework are more important.
If it is true that the NLU performance of the chatbots is roughly the same for all frameworks, then a framework cannot be chosen because of the NLU performance.
Yet, it is the evaluation found in most papers if there is an evaluation at all. 

Common chatbot technologies found in the articles and books are Dialogflow, LUIS,  Rasa, Watson, and Wit.ai.
Dialogflow, LUIS, Rasa, Watson Assistant are used in this thesis.
% ---------------------------- HERE ---------------------------- %